{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5OSPNuYT8F-o"
      },
      "outputs": [],
      "source": [
        "# Import the libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Seeding"
      ],
      "metadata": {
        "id": "kwNBh-BW9ZRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"PYTHONHASHSEED\"] = str(42)\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "rJrkoPpl8y9t"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Hyperparameters"
      ],
      "metadata": {
        "id": "_ZSLoVmE9bMA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting hyperparameters for the model"
      ],
      "metadata": {
        "id": "UMkpMnRutrMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "lr = 0.0001\n",
        "epochs = 100\n",
        "height = 256\n",
        "width = 256"
      ],
      "metadata": {
        "id": "yl6IBl-39KOD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Path"
      ],
      "metadata": {
        "id": "FGhmo54b9dPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = os.path.join('/content/drive/MyDrive/US dataset/Original without duplicated, misclassification and axila/Owdma')"
      ],
      "metadata": {
        "id": "ctLwhBh99Tpa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Unet"
      ],
      "metadata": {
        "id": "2MiGzDMTAz3N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the architecture of the U-Net model"
      ],
      "metadata": {
        "id": "FSmtVlFpt6sm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(inputs, num_filters):\n",
        "  x = Conv2D(num_filters, 3, padding='same')(inputs)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  x = Conv2D(num_filters, 3, padding='same')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  return x"
      ],
      "metadata": {
        "id": "otibRsSzAzXa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_block(inputs, num_filters):\n",
        "  x = conv_block(inputs, num_filters)\n",
        "  p = MaxPool2D((2, 2))(x)\n",
        "  return x, p"
      ],
      "metadata": {
        "id": "h_GYaVndBS3a"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder_block(inputs, skip, num_filters):\n",
        "  x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding='same')(inputs)\n",
        "  x = Concatenate()([x, skip])\n",
        "  x = conv_block(x, num_filters)\n",
        "\n",
        "  return x"
      ],
      "metadata": {
        "id": "kceoJBZ7Bj-W"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_unet(input_shape):\n",
        "  inputs = Input(input_shape)\n",
        "\n",
        "  \"\"\" Encoder\"\"\"\n",
        "  s1, p1 = encoder_block(inputs, 64)\n",
        "  s2, p2 = encoder_block(p1, 128)\n",
        "  s3, p3 = encoder_block(p2, 256)\n",
        "  s4, p4 = encoder_block(p3, 512)\n",
        "\n",
        "  \"\"\" Bridge \"\"\"\n",
        "  b1 = conv_block(p4, 1024)\n",
        "\n",
        "  \"\"\" Decoder \"\"\"\n",
        "  d1 = decoder_block(b1, s4, 512)\n",
        "  d2 = decoder_block(d1, s3, 256)\n",
        "  d3 = decoder_block(d2, s2, 128)\n",
        "  d4 = decoder_block(d3, s1, 64)\n",
        "\n",
        "  outputs = Conv2D(1, 1, padding='same', activation='sigmoid')(d4)\n",
        "\n",
        "  model = Model(inputs, outputs, name='UNet')\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "mtPWLCIFB5__"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Pipeline"
      ],
      "metadata": {
        "id": "Gq60ov_ADIvP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following function is commented because after I have a function for images and another for masks. It is important because we need to do a train set and a test set."
      ],
      "metadata": {
        "id": "VszebO-gwejQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#def load_and_preprocess_images(data_dir):\n",
        "#   images = []\n",
        "#    masks = []\n",
        "#    labels = []\n",
        "\n",
        "#    for class_name, class_label in class_labels.items():\n",
        "#        class_dir = os.path.join(data_dir, class_name)\n",
        "#        for image_file in os.listdir(class_dir):\n",
        "#            if image_file.endswith(\".png\") and 'mask' not in image_file:\n",
        "#                # Load the original image\n",
        "#                image = img_to_array(load_img(os.path.join(class_dir, image_file), target_size=image_size))\n",
        "#                image = image / 255.0  # Normalize pixel values\n",
        "\n",
        "                # Find all masks associated with the image\n",
        "#                image_name = os.path.splitext(image_file)[0]  # Remove the file extension\n",
        "#                matching_masks = [f for f in os.listdir(class_dir) if f.startswith(image_name) and f.endswith(\"_mask.png\") and '_1_mask' not in image_file and '_2_mask' not in image_file]\n",
        "\n",
        "#                for mask_file in matching_masks:\n",
        "#                    mask = img_to_array(load_img(os.path.join(class_dir, mask_file), target_size=image_size, color_mode=\"grayscale\"))\n",
        "#                    mask = mask / 255.0  # Normalize pixel values\n",
        "#                    labels.append(class_label)\n",
        "\n",
        "#                    images.append(image)\n",
        "#                    masks.append(mask)\n",
        "\n",
        "#    return images, masks, labels"
      ],
      "metadata": {
        "id": "sum5SKqFvfLm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the data using the defined function\n",
        "data_dir = \"/content/drive/MyDrive/US dataset/Original without duplicated, misclassification and axila/Owdma\"\n",
        "class_labels = {\"normal\": 0, \"benign\": 1, \"malignant\": 2}\n",
        "image_size = (height, width)\n",
        "#images, masks, labels = load_and_preprocess_images(data_dir)"
      ],
      "metadata": {
        "id": "e4k0LhAsHQbH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_image(path):\n",
        "  for class_name, class_label in class_labels.items():\n",
        "        class_dir = os.path.join(data_dir, class_name)\n",
        "        for image_file in os.listdir(class_dir):\n",
        "            if image_file.endswith(\".png\") and 'mask' not in image_file:\n",
        "                # Load the original image\n",
        "                image = img_to_array(load_img(os.path.join(class_dir, image_file), target_size=image_size))\n",
        "                image = image / 255.0  # Normalize pixel values\n",
        "  return image"
      ],
      "metadata": {
        "id": "BTit4n_XMdbS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = read_image(data_dir)"
      ],
      "metadata": {
        "id": "Zv9wbMSQW-C7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_mask(path):\n",
        "  for class_name, class_label in class_labels.items():\n",
        "        class_dir = os.path.join(data_dir, class_name)\n",
        "        for image_file in os.listdir(class_dir):\n",
        "          # Find all masks associated with the image\n",
        "              image_name = os.path.splitext(image_file)[0]  # Remove the file extension\n",
        "              matching_masks = [f for f in os.listdir(class_dir) if f.startswith(image_name) and f.endswith(\"_mask.png\") and '_1_mask' not in image_file and '_2_mask' not in image_file]\n",
        "\n",
        "              for mask_file in matching_masks:\n",
        "                  mask = img_to_array(load_img(os.path.join(class_dir, mask_file), target_size=image_size, color_mode=\"grayscale\"))\n",
        "                  mask = mask / 255.0  # Normalize pixel values\n",
        "  return mask"
      ],
      "metadata": {
        "id": "QZ7BYbaeMvgQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = read_mask(data_dir)"
      ],
      "metadata": {
        "id": "dDOvmj_tW4HW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_valid_split(images, masks):\n",
        "    num_samples = len(images)\n",
        "    split_index = int(0.8 * num_samples)\n",
        "\n",
        "    train_x = images[:split_index]\n",
        "    valid_x = images[split_index:]\n",
        "\n",
        "    train_y = masks[:split_index]\n",
        "    valid_y = masks[split_index:]\n",
        "\n",
        "    return train_x, valid_x, train_y, valid_y"
      ],
      "metadata": {
        "id": "SQp_ol2SUQ0A"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tf_parse(image, mask):\n",
        "    def _parse(x, y):\n",
        "      x = read_image(x)\n",
        "      y = read_mask(y)\n",
        "      return x, y\n",
        "\n",
        "    x, y = tf.numpy_function(_parse, [x, y], [tf.float64, tf.float64])\n",
        "    x.set_shape([height, width, 3])\n",
        "    y.set_shape([height, width, 1])\n",
        "\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "_9Gg8ooiISs4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tf_dataset(images, masks, batch=8):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((images, masks))\n",
        "  dataset = dataset.map(tf_parse, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "  dataset = dataset.batch(batch)\n",
        "  dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "i95_PolIN4xW"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training"
      ],
      "metadata": {
        "id": "imV3lBkNUzLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, valid_x, train_y, valid_y = train_valid_split(images, masks)"
      ],
      "metadata": {
        "id": "xrWTPaOZPBNN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_x))\n",
        "print(len(train_y))\n",
        "print(len(valid_x))\n",
        "print(len(valid_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5XSiNVfVSTY",
        "outputId": "e02c6e64-24cc-4b8c-cef8-d5c363f7ebb0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "439\n",
            "439\n",
            "110\n",
            "110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Combine train_x and train_y into train_dataset\n",
        "#train_dataset = pd.DataFrame({'images': train_x,\n",
        "#                              'masks': train_y})\n",
        "\n",
        "# Combine valid_x and valid_y into valid_dataset\n",
        "#valid_dataset = pd.DataFrame({'images': valid_x,\n",
        "#                              'masks': valid_y})"
      ],
      "metadata": {
        "id": "fvB3FFc8ok1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the code that I used to convert the np array to tensor. But it outputs a flattened array that cannot be used in the model. The code that is below is the one that the guy of the video used to transform the train and test set to tensors."
      ],
      "metadata": {
        "id": "ErEq0tXQxGA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Combine train_x and train_y into train_dataset\n",
        "train_dataset = pd.DataFrame({'images': [x.flatten() for x in train_x],\n",
        "                              'masks': [y.flatten() for y in train_y]})\n",
        "\n",
        "# Combine valid_x and valid_y into valid_dataset\n",
        "valid_dataset = pd.DataFrame({'images': [x.flatten() for x in valid_x],\n",
        "                              'masks': [y.flatten() for y in valid_y]})"
      ],
      "metadata": {
        "id": "eEbCKhVAt6xD"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = tf.convert_to_tensor(train_dataset['images'].values.tolist())\n",
        "train_masks = tf.convert_to_tensor(train_dataset['masks'].values.tolist())\n",
        "valid_images = tf.convert_to_tensor(valid_dataset['images'].values.tolist())\n",
        "valid_masks = tf.convert_to_tensor(valid_dataset['masks'].values.tolist())\n",
        "\n",
        "# Create TensorFlow datasets\n",
        "train_dataset_tf = tf.data.Dataset.from_tensor_slices((train_images, train_masks))\n",
        "valid_dataset_tf = tf.data.Dataset.from_tensor_slices((valid_images, valid_masks))"
      ],
      "metadata": {
        "id": "TlkDpPpAo5pN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (height, width, 3)\n",
        "model = build_unet(input_shape)"
      ],
      "metadata": {
        "id": "MENqOSEiWG5K"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c9vi2EbXpsy",
        "outputId": "bf662a23-aec4-4b8b-ee8b-1b6d6c68eb51"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"UNet\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 512, 512, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)          (None, 512, 512, 64)         1792      ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_18 (Ba  (None, 512, 512, 64)         256       ['conv2d_19[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_18 (Activation)  (None, 512, 512, 64)         0         ['batch_normalization_18[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)          (None, 512, 512, 64)         36928     ['activation_18[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_19 (Ba  (None, 512, 512, 64)         256       ['conv2d_20[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_19 (Activation)  (None, 512, 512, 64)         0         ['batch_normalization_19[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPoolin  (None, 256, 256, 64)         0         ['activation_19[0][0]']       \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)          (None, 256, 256, 128)        73856     ['max_pooling2d_4[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_20 (Ba  (None, 256, 256, 128)        512       ['conv2d_21[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_20 (Activation)  (None, 256, 256, 128)        0         ['batch_normalization_20[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)          (None, 256, 256, 128)        147584    ['activation_20[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_21 (Ba  (None, 256, 256, 128)        512       ['conv2d_22[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_21 (Activation)  (None, 256, 256, 128)        0         ['batch_normalization_21[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPoolin  (None, 128, 128, 128)        0         ['activation_21[0][0]']       \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)          (None, 128, 128, 256)        295168    ['max_pooling2d_5[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_22 (Ba  (None, 128, 128, 256)        1024      ['conv2d_23[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_22 (Activation)  (None, 128, 128, 256)        0         ['batch_normalization_22[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)          (None, 128, 128, 256)        590080    ['activation_22[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_23 (Ba  (None, 128, 128, 256)        1024      ['conv2d_24[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_23 (Activation)  (None, 128, 128, 256)        0         ['batch_normalization_23[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPoolin  (None, 64, 64, 256)          0         ['activation_23[0][0]']       \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)          (None, 64, 64, 512)          1180160   ['max_pooling2d_6[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_24 (Ba  (None, 64, 64, 512)          2048      ['conv2d_25[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_24 (Activation)  (None, 64, 64, 512)          0         ['batch_normalization_24[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)          (None, 64, 64, 512)          2359808   ['activation_24[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_25 (Ba  (None, 64, 64, 512)          2048      ['conv2d_26[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_25 (Activation)  (None, 64, 64, 512)          0         ['batch_normalization_25[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPoolin  (None, 32, 32, 512)          0         ['activation_25[0][0]']       \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)          (None, 32, 32, 1024)         4719616   ['max_pooling2d_7[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_26 (Ba  (None, 32, 32, 1024)         4096      ['conv2d_27[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_26 (Activation)  (None, 32, 32, 1024)         0         ['batch_normalization_26[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)          (None, 32, 32, 1024)         9438208   ['activation_26[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_27 (Ba  (None, 32, 32, 1024)         4096      ['conv2d_28[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_27 (Activation)  (None, 32, 32, 1024)         0         ['batch_normalization_27[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_4 (Conv2D  (None, 64, 64, 512)          2097664   ['activation_27[0][0]']       \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate  (None, 64, 64, 1024)         0         ['conv2d_transpose_4[0][0]',  \n",
            " )                                                                   'activation_25[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)          (None, 64, 64, 512)          4719104   ['concatenate_4[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_28 (Ba  (None, 64, 64, 512)          2048      ['conv2d_29[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_28 (Activation)  (None, 64, 64, 512)          0         ['batch_normalization_28[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)          (None, 64, 64, 512)          2359808   ['activation_28[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_29 (Ba  (None, 64, 64, 512)          2048      ['conv2d_30[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_29 (Activation)  (None, 64, 64, 512)          0         ['batch_normalization_29[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_5 (Conv2D  (None, 128, 128, 256)        524544    ['activation_29[0][0]']       \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate  (None, 128, 128, 512)        0         ['conv2d_transpose_5[0][0]',  \n",
            " )                                                                   'activation_23[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)          (None, 128, 128, 256)        1179904   ['concatenate_5[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_30 (Ba  (None, 128, 128, 256)        1024      ['conv2d_31[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_30 (Activation)  (None, 128, 128, 256)        0         ['batch_normalization_30[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)          (None, 128, 128, 256)        590080    ['activation_30[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_31 (Ba  (None, 128, 128, 256)        1024      ['conv2d_32[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_31 (Activation)  (None, 128, 128, 256)        0         ['batch_normalization_31[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_6 (Conv2D  (None, 256, 256, 128)        131200    ['activation_31[0][0]']       \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate  (None, 256, 256, 256)        0         ['conv2d_transpose_6[0][0]',  \n",
            " )                                                                   'activation_21[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)          (None, 256, 256, 128)        295040    ['concatenate_6[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_32 (Ba  (None, 256, 256, 128)        512       ['conv2d_33[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_32 (Activation)  (None, 256, 256, 128)        0         ['batch_normalization_32[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)          (None, 256, 256, 128)        147584    ['activation_32[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_33 (Ba  (None, 256, 256, 128)        512       ['conv2d_34[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_33 (Activation)  (None, 256, 256, 128)        0         ['batch_normalization_33[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_transpose_7 (Conv2D  (None, 512, 512, 64)         32832     ['activation_33[0][0]']       \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate  (None, 512, 512, 128)        0         ['conv2d_transpose_7[0][0]',  \n",
            " )                                                                   'activation_19[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)          (None, 512, 512, 64)         73792     ['concatenate_7[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_34 (Ba  (None, 512, 512, 64)         256       ['conv2d_35[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_34 (Activation)  (None, 512, 512, 64)         0         ['batch_normalization_34[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)          (None, 512, 512, 64)         36928     ['activation_34[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_35 (Ba  (None, 512, 512, 64)         256       ['conv2d_36[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_35 (Activation)  (None, 512, 512, 64)         0         ['batch_normalization_35[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)          (None, 512, 512, 1)          65        ['activation_35[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31055297 (118.47 MB)\n",
            "Trainable params: 31043521 (118.42 MB)\n",
            "Non-trainable params: 11776 (46.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = tf.keras.optimizers.Adam(lr)\n",
        "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['acc'])"
      ],
      "metadata": {
        "id": "ocUJHaLIYJKC"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code that follows uses: (1) reduce LR on plateau: when the loss function on the validation set does not imporve in 4 epochs, the LR is reduced by a factor of 0.1. And (2) the early stopping if in 20 epochs the loss function on the validation set does not improve, it stops the algorithm."
      ],
      "metadata": {
        "id": "VCPbKvuLxhUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4),\n",
        "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False)\n",
        "]"
      ],
      "metadata": {
        "id": "STvXRnDVYYtn"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_dataset_tf,\n",
        "    validation_data=valid_dataset_tf,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "id": "JUC-Ppo2Z77I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "outputId": "3e1927e7-6d9b-4421-81e6-a728f25995a9"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-83f20343b36c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_dataset_tf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_dataset_tf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1126, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'UNet' (type Functional).\n    \n    Input 0 of layer \"conv2d_19\" is incompatible with the layer: expected min_ndim=4, found ndim=1. Full shape received: (786432,)\n    \n    Call arguments received by layer 'UNet' (type Functional):\n      • inputs=tf.Tensor(shape=(786432,), dtype=float32)\n      • training=True\n      • mask=None\n"
          ]
        }
      ]
    }
  ]
}